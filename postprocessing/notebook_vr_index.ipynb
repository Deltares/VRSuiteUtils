{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35352a3f",
   "metadata": {},
   "source": [
    "This notebook gives an example of how one can analyze different runs in the same database. \n",
    "This is for instance relevant if multiple analysis with veiligheidsrendement are made for the same traject."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746917ce-1090-4f5f-83c2-c5af70a80faa",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9b85c72-0b27-4530-97c4-3b1443ac1b81",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from peewee import fn\n",
    "from collections import defaultdict\n",
    "from vrtool.orm.models import *\n",
    "from vrtool.orm.orm_controllers import open_database\n",
    "from vrtool.common.enums import MechanismEnum\n",
    "from postprocessing.database_analytics import *\n",
    "from postprocessing.database_access_functions import * \n",
    "from postprocessing.generate_output import *\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "colors = sns.color_palette(\"colorblind\", 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d4b5e2-745d-4adc-9539-5d4c224ecf32",
   "metadata": {},
   "source": [
    "### Get the runs that are in the database\n",
    "First we get an overview of the runs in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a768e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_path = Path(r'c:\\Users\\rikkert\\OneDrive - Stichting Deltares\\Desktop\\dec2024_backup_C\\VRM\\traject10_voor_handreiking\\10-2\\database_10-2.sqlite')\n",
    "run_list = get_overview_of_runs(database_path)\n",
    "run_list = [run for run in run_list if run['optimization_type_name']== 'VEILIGHEIDSRENDEMENT']\n",
    "pd.DataFrame(run_list)\n",
    "print(run_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a608a1da",
   "metadata": {},
   "source": [
    "For each run, we get the optimization steps and the step with minimal total cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "917433c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_steps = {run['name']: get_optimization_steps_for_run_id(database_path, run['id']) for run in run_list}\n",
    "# add total cost as sum of total_lcc and total_risk in each step\n",
    "\n",
    "minimal_tc_steps = {run: get_minimal_tc_step(steps) for run, steps in optimization_steps.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edb8c43",
   "metadata": {},
   "source": [
    "### Reading measures per step\n",
    "The next step is to read the measures and parameters of these measures for each optimization step such that we can compare the measures that are taken in each step and for each section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "354ee97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lists_of_measures = {run['id']: get_measures_for_run_id(database_path, run['id']) for run in run_list}\n",
    "\n",
    "measures_per_step = {run['id']: get_measures_per_step_number(lists_of_measures[run['id']]) for run in run_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43463ead",
   "metadata": {},
   "source": [
    "If we want to see the failure probability per stap we first need to load the original assessment for each mechanism, and then we can compute the reliability for each step during the optimization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2963f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_results = {mechanism: import_original_assessment(database_path, mechanism) \n",
    "                      for mechanism in [MechanismEnum.OVERFLOW, MechanismEnum.PIPING, MechanismEnum.STABILITY_INNER]}\n",
    "\n",
    "reliability_per_step = {run['id']: get_reliability_for_each_step(database_path, measures_per_step[run['id']]) for run in run_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6134da",
   "metadata": {},
   "source": [
    "Based on these inputs we can make a stepwise_assessment based on the investments in reliability_per_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "936221a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_assessment = {run['id']: assessment_for_each_step(copy.deepcopy(assessment_results), reliability_per_step[run['id']]) for run in run_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28078569",
   "metadata": {},
   "source": [
    "The next step is to derive the traject probability for each mechanism for each step using the `calculate_traject_probability_for_steps` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d1c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "traject_prob = {run['id']: calculate_traject_probability_for_steps(stepwise_assessment[run['id']]) for run in run_list}\n",
    "\n",
    "for count, run in enumerate(run_list):\n",
    "    print(traject_prob[run['id']][minimal_tc_steps[run['name']]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5628e349",
   "metadata": {},
   "source": [
    "Now we check the measures for each section. We print the ids of the measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36afdf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_per_section = {run['id']: get_measures_per_section_for_step(measures_per_step[run['id']], minimal_tc_steps[run['name']]) for run in run_list}\n",
    "section_names = [list(measures_per_section[run].keys()) for run in measures_per_section.keys()]\n",
    "section_names = list(set([item for sublist in section_names for item in sublist]))\n",
    "\n",
    "for section in section_names:\n",
    "    for run in measures_per_section.keys():\n",
    "        try:\n",
    "            print(f\"Section {section} in run {run} has measures {measures_per_section[run][section][0]} at time {measures_per_section[run][section][1]}\")  \n",
    "        except:\n",
    "            print(f\"Section {section} in run {run} has no measures in run {run}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca08be4",
   "metadata": {},
   "source": [
    "Now we get for each section the parameters of the measure + timing + cost. This is stored in a `pd.DataFrame` for each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faab47bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_parameters = defaultdict(dict)\n",
    "\n",
    "for run in measures_per_section.keys():\n",
    "    for section in measures_per_section[run].keys():\n",
    "        section_parameters[run][section] = []\n",
    "        for measure in measures_per_section[run][section][0]:\n",
    "            parameters = get_measure_parameters(measure, database_path)\n",
    "            parameters.update(get_measure_costs(measure, database_path))\n",
    "            parameters.update(get_measure_type(measure, database_path))\n",
    "            # if parameters name is \"Grondversterking binnenwaarts\" and dberm and dcrest are 0, set cost to 0\n",
    "            if parameters['name'] == 'Grondversterking binnenwaarts' and parameters['dberm'] == 0 and parameters['dcrest'] == 0:\n",
    "                print(f\"Setting costs to 0 for measure {parameters['name']} in section {section} in run {run}\")\n",
    "                parameters['cost'] = 0\n",
    "            section_parameters[run][section].append(parameters)\n",
    "\n",
    "measure_parameters = {run['id']: measure_per_section_to_df(measures_per_section[run['id']], section_parameters[run['id']]) for run in run_list}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0d9826",
   "metadata": {},
   "source": [
    "We list the investment for each year for each section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff53d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need final step of stepwise_assessment\n",
    "# and assessment_results for initial state of each section\n",
    "# we also have costs per section.\n",
    "\n",
    "# determine final beta for traject:\n",
    "initial_traject_probability_per_mechanism = calculate_traject_probability(assessment_results)\n",
    "print(f\"Initial traject probability is {initial_traject_probability_per_mechanism}\")\n",
    "\n",
    "n_time_steps = len(initial_traject_probability_per_mechanism[MechanismEnum.OVERFLOW])\n",
    "time_steps = initial_traject_probability_per_mechanism[MechanismEnum.OVERFLOW].keys()\n",
    "print(f\"Number of time steps is {n_time_steps}\")\n",
    "print(f\"Time steps are {time_steps}\")\n",
    "\n",
    "# print final step of stepwise_assessment (at minimal_tc_steps):\n",
    "for count, run in enumerate(run_list):\n",
    "    final_traject_probability_per_mechanism = traject_prob[run['id']][minimal_tc_steps[run['name']]]\n",
    "    final_section_probability_per_mechanism = stepwise_assessment[run['id']][minimal_tc_steps[run['name']]]\n",
    "\n",
    "print(f\"Final traject probability is {final_traject_probability_per_mechanism}\")\n",
    "print(f\"Final section probability is {final_section_probability_per_mechanism}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e2f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from the database the economic damage, which is found in DikeTrajectInfo, and called flood_damage\n",
    "# there is only 1 value in total, so we can use the first value\n",
    "\n",
    "with open_database(database_path) as db:\n",
    "    damage = DikeTrajectInfo.select(DikeTrajectInfo.flood_damage).where(DikeTrajectInfo.id == 1).get().flood_damage\n",
    "\n",
    "print(f\"Damage is {damage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955ce978",
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_rate = 0.03\n",
    "\n",
    "damage_per_year = np.divide(damage, np.power(1+discount_rate, np.arange(0,100)))\n",
    "damage_per_year = damage_per_year.reshape(1,100)\n",
    "print(damage_per_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378859a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that calculates total risk, given traject reliability per mechanism, damage and annual discount rate\n",
    "\n",
    "def calculate_total_risk(traject_reliability, damage, discount_rate):\n",
    "    n_years = 100\n",
    "    damage_per_year = np.divide(damage, np.power(1+discount_rate, np.arange(0,n_years)))\n",
    "    damage_per_year = damage_per_year.reshape(1,n_years)\n",
    "    total_non_failure_probability = np.ones([1,n_years])\n",
    "    traject_reliability_interp = {}\n",
    "    for key in traject_reliability.keys():\n",
    "        times,betas = zip(*traject_reliability[key].items())\n",
    "        time_beta_interpolation = interp1d(times, betas, kind='linear', fill_value='extrapolate')\n",
    "        traject_reliability_interp[key] = time_beta_interpolation(list(range(0,100)))\n",
    "        traject_reliability_interp[key] = np.array(traject_reliability_interp[key]).reshape(1,100)\n",
    "    for key in traject_reliability_interp.keys():\n",
    "        total_non_failure_probability = np.multiply(total_non_failure_probability, 1-traject_reliability_interp[key])\n",
    "    total_failure_probability = 1 - total_non_failure_probability\n",
    "    expected_risk_per_year = np.multiply(damage_per_year, total_failure_probability)\n",
    "    total_risk = np.sum(expected_risk_per_year)\n",
    "    print(f\"Total risk is {int(total_risk)}\")\n",
    "    return total_risk\n",
    "\n",
    "total_risk = calculate_total_risk(final_traject_probability_per_mechanism, damage, discount_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2e8e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward VRM index calculation:\n",
    "# section by section, replace the final traject probability by the initial traject probability of that section\n",
    "# then recalculate the traject failure probability, and calculate the increase in risk. We find the VR-index by dividing the increase in risk by the costs of the measure\n",
    "\n",
    "# create empty lists and dictionaries\n",
    "increase_in_traject_risk = []\n",
    "section_costs = []\n",
    "vr_index = {}\n",
    "\n",
    "for section in section_names:\n",
    "    final_section_probability_per_mechanism_temp = copy.deepcopy(final_section_probability_per_mechanism)\n",
    "\n",
    "    for mechanism in assessment_results.keys():\n",
    "        final_section_probability_per_mechanism_temp[mechanism][section]['beta'] = assessment_results[mechanism][section]['beta']\n",
    "\n",
    "    # recalculate final traject probability\n",
    "    final_traject_probability_per_mechanism_temp = calculate_traject_probability(final_section_probability_per_mechanism_temp)\n",
    "    \n",
    "    # calculate_total_risk\n",
    "    risk_increased = calculate_total_risk(final_traject_probability_per_mechanism_temp, damage, discount_rate) \n",
    "    delta_risk = risk_increased - total_risk\n",
    "\n",
    "    if section in list(measure_parameters[1]['section_id']):\n",
    "        if measure_parameters[1][(measure_parameters[1]['section_id'] == section) & (measure_parameters[1]['name'] == 'Grondversterking binnenwaarts') & (measure_parameters[1]['dcrest'] == 0) & (measure_parameters[1]['dberm'] == 0)].shape[0] > 0:\n",
    "            print(f\"Section {section} has grondversterking 0/0\")\n",
    "            vr_index[section] = 0\n",
    "        else:\n",
    "            section_costs = measure_parameters[1][measure_parameters[1]['section_id'] == section]['LCC'].values[0]\n",
    "            vr_index[section] = delta_risk / section_costs\n",
    "    else:\n",
    "        vr_index[section] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaf8c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_parameters[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38734781",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vr_index)\n",
    "\n",
    "# sort the dictionary by value\n",
    "sorted_vr_index = dict(sorted(vr_index.items(), key=lambda item: item[1], reverse=True))\n",
    "print(sorted_vr_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b83c7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a101fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0b968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_reliability_assessment_list = get_section_assessment_results(database_path)\n",
    "print(section_reliability_assessment_list)\n",
    "\n",
    "# get beta for each section at 'time'\n",
    "time = 25\n",
    "\n",
    "section_reliability_assessment_list = [section for section in section_reliability_assessment_list if section['time'] == time]\n",
    "print(section_reliability_assessment_list)\n",
    "\n",
    "for section_data in section_reliability_assessment_list:\n",
    "    section_data['Pf'] = norm.cdf(-section_data['beta'])\n",
    "\n",
    "# sort the list based on Pf and print sorted list in descending order\n",
    "section_reliability_assessment_list_sorted_pf = sorted(section_reliability_assessment_list, key=lambda k: k['Pf'], reverse=True)\n",
    "print(section_reliability_assessment_list_sorted_pf)\n",
    "\n",
    "# print section ids and Pf\n",
    "print()\n",
    "for section in section_reliability_assessment_list_sorted_pf:\n",
    "    print(f\"section_id: {section['section_data']}, Pf: {section['Pf']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59355969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pandas dataframe with all sections in database that are inanalyse = True\n",
    "\n",
    "def get_sections_in_analysis(database_path):\n",
    "    with open_database(database_path) as db:\n",
    "        sections = SectionData.select().where(SectionData.in_analysis == True)\n",
    "        sections_analysis = pd.DataFrame()\n",
    "        # add section.section_name to the dataframe, using pandas concat\n",
    "        for section in sections:\n",
    "            sections_analysis = pd.concat([sections_analysis, pd.DataFrame({'id': [int(section.id)], 'section_name': [section.section_name]})], ignore_index=True)\n",
    "            # sections_analysis = pd.concat([sections_analysis, pd.DataFrame({'section_name': [section.section_name]})], ignore_index=True)\n",
    "        # section names are sometimes integers, sometimes strings. Try to make them integers if possible\n",
    "        try:\n",
    "            sections_analysis['section_name'] = sections_analysis['section_name'].astype(int)\n",
    "        except:\n",
    "            pass\n",
    "    return sections_analysis\n",
    "\n",
    "sections_analysis = get_sections_in_analysis(database_path)\n",
    "\n",
    "print(sections_analysis)\n",
    "print(sections_analysis.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965bfccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_reliability_assessment_list = get_section_assessment_results(database_path)\n",
    "\n",
    "# get beta for each section at 'time'\n",
    "time = 25\n",
    "section_reliability_assessment_list = [section for section in section_reliability_assessment_list if section['time'] == time]\n",
    "\n",
    "# each item in the section_reliability_assessment_list is a dictionary with keys: id, section_data, beta, time. I want to remove 'id'\n",
    "section_reliability_assessment_list = [{k: v for k, v in section.items() if k != 'id'} for section in section_reliability_assessment_list]\n",
    "\n",
    "# add Pf to each key, based on beta. Pf = scipy.stats.norm.cdf(-beta)\n",
    "for section_data in section_reliability_assessment_list:\n",
    "    section_data['Pf'] = norm.cdf(-section_data['beta'])\n",
    "\n",
    "print(section_reliability_assessment_list)\n",
    "\n",
    "# add the probabilities to the sections_analysis dataframe where section_reliability_assessment_list [section_data] equals sections_analysis [section_name]\n",
    "for section_data in section_reliability_assessment_list:\n",
    "    sections_analysis.loc[sections_analysis['id'] == section_data['section_data'], f'Pf_init_t{time}'] = section_data['Pf']\n",
    "\n",
    "print(sections_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e974060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the vr_index to the sections_analysis dataframe where sorted_vr_index.keys() sections_analysis [section_name]. Also add a ranking based on the order in which the id comes first in sorted_vr_index\n",
    "for count, section in enumerate(sorted_vr_index.keys()):\n",
    "    sections_analysis.loc[sections_analysis['id'] == section, 'vr_index'] = sorted_vr_index[section]\n",
    "    sections_analysis.loc[sections_analysis['id'] == section, 'vr_index_ranking'] = count+1 \n",
    "\n",
    "# replace all NAN values in vr_index and vr_index_ranking with -999. Set the type for vr_index_ranking to int\n",
    "sections_analysis['vr_index'] = sections_analysis['vr_index'].fillna(-999)\n",
    "sections_analysis['vr_index_ranking'] = sections_analysis['vr_index_ranking'].fillna(-999)\n",
    "sections_analysis['vr_index_ranking'] = sections_analysis['vr_index_ranking'].astype(int)\n",
    "\n",
    "print(sections_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forward_vr_order(measures_per_step):\n",
    "        forward_vr_order = [step['section_id'][0] for _idx, (step) in enumerate(measures_per_step[run['id']].values()) if _idx <= minimal_tc_steps[run['name']]]\n",
    "        #take first of unique values, keep order\n",
    "        forward_vr_order = [x for i, x in enumerate(forward_vr_order) if forward_vr_order.index(x) == i]\n",
    "        return forward_vr_order\n",
    "\n",
    "order_forward_vr = get_forward_vr_order(measures_per_step)\n",
    "\n",
    "print(order_forward_vr)\n",
    "\n",
    "# add the forward_vr_order to the sections_analysis dataframe where order_forward_vr equals sections_analysis [id]\n",
    "for count, section in enumerate(order_forward_vr):\n",
    "    sections_analysis.loc[sections_analysis['id'] == section, 'forward_vr_order'] = count+1\n",
    "\n",
    "# replace all NAN values in forward_vr_order with -999. Set the type for forward_vr_order to int\n",
    "sections_analysis['forward_vr_order'] = sections_analysis['forward_vr_order'].fillna(-999)\n",
    "sections_analysis['forward_vr_order'] = sections_analysis['forward_vr_order'].astype(int)\n",
    "\n",
    "print(sections_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bd45d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vr_preprocessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
